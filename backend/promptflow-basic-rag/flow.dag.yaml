$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
    default: Tell me about perks plus
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: open_ai_connection
    deployment_name: text-embedding-large
    input: ${inputs.question}
- name: azure_vector_search
  type: python
  source:
    type: code
    path: azure_search.py
  inputs:
    connection: ai_search_connection
    index_name: vector-1723820968453
    vectorQuery: ${embed_the_question.output}
- name: generate_prompt_from_search_results
  type: python
  source:
    type: code
    path: generate_prompt_context_from_search_result.py
  inputs:
    search_results: ${azure_vector_search.output}
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: gpt-4o
    max_tokens: 1000
    temperature: 0.7
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    contexts: ${generate_prompt_from_search_results.output}
  connection: open_ai_connection
  api: chat
